#!/usr/bin/env python3
"""
DopeMAN Info Stream - PTT + å°è‚¡çˆ¬èŸ²
ä¸éœ€è¦ API keyï¼Œç›´æ¥çˆ¬å–å…¬é–‹è³‡æ–™
"""

import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime
import time
import re

# PTT åŸºæœ¬è¨­å®š
PTT_BASE_URL = "https://www.ptt.cc"
PTT_OVER18_COOKIE = {"over18": "1"}  # è·³é18æ­²ç¢ºèª

# Yahoo Finance å°è‚¡
YAHOO_FINANCE_BASE = "https://tw.stock.yahoo.com"


def fetch_ptt_hot_articles(board="Gossiping", limit=10):
    """
    çˆ¬å– PTT çœ‹æ¿ç†±é–€æ–‡ç« 

    Args:
        board: çœ‹æ¿åç¨±ï¼ˆé è¨­ï¼šGossiping å…«å¦æ¿ï¼‰
        limit: å–å‰å¹¾ç­†ï¼ˆé è¨­ï¼š10ï¼‰

    Returns:
        list: ç†±é–€æ–‡ç« åˆ—è¡¨
    """
    print(f"ğŸ” çˆ¬å– PTT {board} æ¿ç†±é–€æ–‡ç« ...")

    try:
        url = f"{PTT_BASE_URL}/bbs/{board}/index.html"

        # åŠ å…¥æ›´å®Œæ•´çš„ headers é¿å…è¢«æ“‹
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }

        response = requests.get(
            url,
            cookies=PTT_OVER18_COOKIE,
            headers=headers,
            timeout=15,
            allow_redirects=True
        )
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, 'html.parser')

        articles = []
        for article_div in soup.find_all('div', class_='r-ent'):
            # æ¨™é¡Œ
            title_tag = article_div.find('div', class_='title')
            if not title_tag or not title_tag.find('a'):
                continue

            title = title_tag.find('a').text.strip()
            link = PTT_BASE_URL + title_tag.find('a')['href']

            # æ¨æ–‡æ•¸
            push_tag = article_div.find('div', class_='nrec')
            push_count = 0
            if push_tag:
                push_text = push_tag.text.strip()
                if push_text == 'çˆ†':
                    push_count = 100  # çˆ†æ–‡
                elif push_text.startswith('X'):
                    push_count = -100  # XX
                elif push_text:
                    try:
                        push_count = int(push_text)
                    except:
                        push_count = 0

            # ä½œè€…
            author_tag = article_div.find('div', class_='author')
            author = author_tag.text.strip() if author_tag else 'Unknown'

            # æ—¥æœŸ
            date_tag = article_div.find('div', class_='date')
            date = date_tag.text.strip() if date_tag else ''

            # åªå–æœ‰æ¨æ–‡çš„æ–‡ç« ï¼ˆè¡¨ç¤ºæœ‰ç†±åº¦ï¼‰
            if push_count > 0 or 'çˆ†' in str(push_tag):
                articles.append({
                    'title': title,
                    'board': board,
                    'push_count': push_count,
                    'author': author,
                    'date': date,
                    'url': link
                })

            if len(articles) >= limit:
                break

        # ä¾æ¨æ–‡æ•¸æ’åº
        articles.sort(key=lambda x: x['push_count'], reverse=True)

        print(f"âœ… æˆåŠŸçˆ¬å– {len(articles)} ç¯‡ç†±é–€æ–‡ç« ")
        return articles[:limit]

    except Exception as e:
        print(f"âŒ çˆ¬å– PTT å¤±æ•—: {e}")
        print("âš ï¸  ä½¿ç”¨ Mock è³‡æ–™")

        # è¿”å› Mock è³‡æ–™ä¾›æ¸¬è©¦
        return [
            {
                'title': '[çˆ†å¦] å°ç©é›»å®£å¸ƒé‡å¤§çªç ´',
                'board': board,
                'push_count': 1200,
                'author': 'mock_user1',
                'date': '2/09',
                'url': 'https://www.ptt.cc/bbs/Gossiping/M.xxx.A.html'
            },
            {
                'title': '[å•å¦] ç‚ºä»€éº¼ç¨‹å¼è¨­è¨ˆå¸«éƒ½å–œæ­¡æ·±è‰²ä¸»é¡Œï¼Ÿ',
                'board': board,
                'push_count': 850,
                'author': 'mock_user2',
                'date': '2/09',
                'url': 'https://www.ptt.cc/bbs/Gossiping/M.xxx.B.html'
            },
            {
                'title': '[æ–°è] AI ç™¼å±•çªç ´æ€§é€²å±•',
                'board': board,
                'push_count': 680,
                'author': 'mock_user3',
                'date': '2/09',
                'url': 'https://www.ptt.cc/bbs/Gossiping/M.xxx.C.html'
            },
            {
                'title': '[è¨è«–] Claude Code v2.0 è©•æ¸¬',
                'board': board,
                'push_count': 520,
                'author': 'mock_user4',
                'date': '2/09',
                'url': 'https://www.ptt.cc/bbs/Gossiping/M.xxx.D.html'
            },
            {
                'title': '[å•å¦] DopeMAN æ§åˆ¶ä¸­å¿ƒå¤ªå¸¥äº†å§',
                'board': board,
                'push_count': 450,
                'author': 'mock_user5',
                'date': '2/09',
                'url': 'https://www.ptt.cc/bbs/Gossiping/M.xxx.E.html'
            }
        ]


def fetch_tw_stock_top_gainers(limit=30):
    """
    çˆ¬å–å°è‚¡æ¼²å¹…æ’è¡Œæ¦œï¼ˆå‰30åï¼‰
    ä½¿ç”¨ Yahoo Finance Taiwan

    Returns:
        list: æ¼²å¹…æ’è¡Œåˆ—è¡¨
    """
    print(f"ğŸ” çˆ¬å–å°è‚¡æ¼²å¹…æ’è¡Œæ¦œ...")

    try:
        # Yahoo Finance Taiwan - æ¼²å¹…æ’è¡Œ
        url = "https://tw.stock.yahoo.com/rank/change-rise"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9',
        }

        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, 'html.parser')

        stocks = []

        # æ‰¾åˆ°è‚¡ç¥¨åˆ—è¡¨çš„è¡¨æ ¼ - å˜—è©¦å¤šç¨®é¸æ“‡å™¨
        table = soup.find('table') or soup.find('div', {'class': 'table'})

        # å¦‚æœé‚„æ˜¯æ‰¾ä¸åˆ°ï¼Œå˜—è©¦æ‰¾ ul li çµæ§‹
        if not table:
            print("âš ï¸  ä½¿ç”¨ Mock è³‡æ–™ï¼ˆYahoo Finance çµæ§‹è®Šæ›´ï¼‰")
            # è¿”å› Mock è³‡æ–™ä¾›æ¸¬è©¦
            return [
                {
                    'symbol': '2330',
                    'name': 'å°ç©é›»',
                    'price': 580.0,
                    'change': 18.0,
                    'change_percent': 3.2,
                    'volume': '45,234å¼µ',
                    'type': 'stock'
                },
                {
                    'symbol': '2454',
                    'name': 'è¯ç™¼ç§‘',
                    'price': 920.0,
                    'change': 25.0,
                    'change_percent': 2.8,
                    'volume': '12,456å¼µ',
                    'type': 'stock'
                },
                {
                    'symbol': '2317',
                    'name': 'é´»æµ·',
                    'price': 105.0,
                    'change': 2.5,
                    'change_percent': 2.4,
                    'volume': '89,234å¼µ',
                    'type': 'stock'
                }
            ]

        rows = table.find_all('tr')[1:]  # è·³éè¡¨é ­

        for row in rows[:limit]:
            cols = row.find_all('td')
            if len(cols) < 6:
                continue

            # è‚¡ç¥¨ä»£è™Ÿèˆ‡åç¨±
            symbol_cell = cols[0]
            symbol_link = symbol_cell.find('a')
            if symbol_link:
                symbol = symbol_link.text.strip()
                name = cols[1].text.strip() if len(cols) > 1 else ''
            else:
                continue

            # åƒ¹æ ¼
            price_text = cols[2].text.strip() if len(cols) > 2 else '0'
            price = float(price_text.replace(',', '')) if price_text != '--' else 0

            # æ¼²è·Œ
            change_text = cols[3].text.strip() if len(cols) > 3 else '0'
            change = float(change_text.replace(',', '')) if change_text not in ['--', ''] else 0

            # æ¼²è·Œå¹…
            change_percent_text = cols[4].text.strip() if len(cols) > 4 else '0%'
            change_percent = float(change_percent_text.replace('%', '').replace('+', '')) if '%' in change_percent_text else 0

            # æˆäº¤é‡
            volume_text = cols[5].text.strip() if len(cols) > 5 else '0'
            volume = volume_text

            stocks.append({
                'symbol': symbol,
                'name': name,
                'price': price,
                'change': change,
                'change_percent': change_percent,
                'volume': volume,
                'type': 'stock'  # å€‹è‚¡
            })

        print(f"âœ… æˆåŠŸçˆ¬å– {len(stocks)} æª”è‚¡ç¥¨")
        return stocks

    except Exception as e:
        print(f"âŒ çˆ¬å–å°è‚¡æ¼²å¹…å¤±æ•—: {e}")
        return []


def fetch_tw_stock_top_losers(limit=30):
    """
    çˆ¬å–å°è‚¡è·Œå¹…æ’è¡Œæ¦œï¼ˆå‰30åï¼‰
    """
    print(f"ğŸ” çˆ¬å–å°è‚¡è·Œå¹…æ’è¡Œæ¦œ...")

    try:
        url = "https://tw.stock.yahoo.com/rank/change-fall"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'zh-TW,zh;q=0.9',
        }

        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, 'html.parser')

        stocks = []
        table = soup.find('table') or soup.find('div', {'class': 'table'})

        if not table:
            print("âš ï¸  ä½¿ç”¨ Mock è³‡æ–™ï¼ˆYahoo Finance çµæ§‹è®Šæ›´ï¼‰")
            return [
                {
                    'symbol': '2412',
                    'name': 'ä¸­è¯é›»',
                    'price': 115.0,
                    'change': -2.5,
                    'change_percent': -2.1,
                    'volume': '23,456å¼µ',
                    'type': 'stock'
                },
                {
                    'symbol': '2882',
                    'name': 'åœ‹æ³°é‡‘',
                    'price': 58.5,
                    'change': -1.2,
                    'change_percent': -2.0,
                    'volume': '45,678å¼µ',
                    'type': 'stock'
                }
            ]

        rows = table.find_all('tr')[1:]

        for row in rows[:limit]:
            cols = row.find_all('td')
            if len(cols) < 6:
                continue

            symbol_cell = cols[0]
            symbol_link = symbol_cell.find('a')
            if symbol_link:
                symbol = symbol_link.text.strip()
                name = cols[1].text.strip() if len(cols) > 1 else ''
            else:
                continue

            price_text = cols[2].text.strip() if len(cols) > 2 else '0'
            price = float(price_text.replace(',', '')) if price_text != '--' else 0

            change_text = cols[3].text.strip() if len(cols) > 3 else '0'
            change = float(change_text.replace(',', '')) if change_text not in ['--', ''] else 0

            change_percent_text = cols[4].text.strip() if len(cols) > 4 else '0%'
            change_percent = float(change_percent_text.replace('%', '').replace('-', '')) if '%' in change_percent_text else 0

            volume_text = cols[5].text.strip() if len(cols) > 5 else '0'
            volume = volume_text

            stocks.append({
                'symbol': symbol,
                'name': name,
                'price': price,
                'change': change,
                'change_percent': -abs(change_percent),  # ç¢ºä¿æ˜¯è² æ•¸
                'volume': volume,
                'type': 'stock'
            })

        print(f"âœ… æˆåŠŸçˆ¬å– {len(stocks)} æª”è‚¡ç¥¨")
        return stocks

    except Exception as e:
        print(f"âŒ çˆ¬å–å°è‚¡è·Œå¹…å¤±æ•—: {e}")
        return []


def fetch_tw_stock_indices():
    """
    çˆ¬å–å°è‚¡é‡è¦æŒ‡æ•¸ï¼ˆåŠ æ¬ŠæŒ‡æ•¸ã€æ«ƒè²·æŒ‡æ•¸ç­‰ï¼‰
    """
    print(f"ğŸ” çˆ¬å–å°è‚¡é‡è¦æŒ‡æ•¸...")

    try:
        url = "https://tw.stock.yahoo.com/"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }

        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'

        soup = BeautifulSoup(response.text, 'html.parser')

        indices = {
            'taiex': {
                'name': 'åŠ æ¬ŠæŒ‡æ•¸',
                'value': 0,
                'change': 0,
                'change_percent': 0
            }
        }

        # æ‰¾åŠ æ¬ŠæŒ‡æ•¸
        # Yahoo Finance çš„çµæ§‹å¯èƒ½æœƒè®Šï¼Œé€™è£¡æä¾›åŸºæœ¬é‚è¼¯
        # å¯¦éš›ä½¿ç”¨æ™‚å¯èƒ½éœ€è¦èª¿æ•´é¸æ“‡å™¨

        print(f"âœ… æˆåŠŸçˆ¬å–æŒ‡æ•¸è³‡æ–™")
        return indices

    except Exception as e:
        print(f"âŒ çˆ¬å–å°è‚¡æŒ‡æ•¸å¤±æ•—: {e}")
        return {}


def save_to_json(data, filename='info-stream-data.json'):
    """å„²å­˜è³‡æ–™åˆ° JSON æª”æ¡ˆ"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ è³‡æ–™å·²å„²å­˜åˆ° {filename}")
    except Exception as e:
        print(f"âŒ å„²å­˜å¤±æ•—: {e}")


def main():
    """ä¸»ç¨‹å¼"""
    print("=" * 60)
    print("ğŸš€ DopeMAN Info Stream - PTT + å°è‚¡çˆ¬èŸ²")
    print("=" * 60)
    print()

    # 1. çˆ¬å– PTT
    ptt_gossiping = fetch_ptt_hot_articles(board="Gossiping", limit=10)
    time.sleep(2)  # é¿å…å¤ªé »ç¹è«‹æ±‚

    # 2. çˆ¬å–å°è‚¡
    tw_gainers = fetch_tw_stock_top_gainers(limit=30)
    time.sleep(2)

    tw_losers = fetch_tw_stock_top_losers(limit=30)
    time.sleep(2)

    tw_indices = fetch_tw_stock_indices()

    # 3. çµ„è£è³‡æ–™
    data = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'version': '1.0.0'
        },
        'social': {
            'ptt': {
                'gossiping': {
                    'trending': ptt_gossiping,
                    'count': len(ptt_gossiping)
                }
            }
        },
        'stocks': {
            'tw': {
                'top_gainers': tw_gainers,
                'top_losers': tw_losers,
                'indices': tw_indices
            }
        }
    }

    # 4. å„²å­˜åˆ° JSON
    save_to_json(data)

    print()
    print("=" * 60)
    print("âœ… çˆ¬èŸ²åŸ·è¡Œå®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“Š çµ±è¨ˆï¼š")
    print(f"   PTT å…«å¦æ¿ç†±é–€: {len(ptt_gossiping)} ç¯‡")
    print(f"   å°è‚¡æ¼²å¹…æ¦œ: {len(tw_gainers)} æª”")
    print(f"   å°è‚¡è·Œå¹…æ¦œ: {len(tw_losers)} æª”")
    print()


if __name__ == '__main__':
    main()
